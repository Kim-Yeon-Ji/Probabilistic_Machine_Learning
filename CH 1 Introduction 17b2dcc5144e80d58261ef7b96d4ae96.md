# CH 1.  Introduction

## 1.1 ML 이란 무엇인가 ?

👨‍🏫 **정의** 

컴퓨터 프로그램이 경험을 통해 학습하고, 그 경험을 통해 작업 성능이 향상된 것

[ 기준 ]

- 시스템이 학습하고자 하는 작업의 성격
- 시스템을 평가하는데 사용하는 성능 측정 기준의 성격
- 시스템에 제공하는 훈련 신호
- 경험의 성격

⇒ 다양한 종류의 ML이 존재

ML은 모든 미지의 수량을 설명하는 확률 분포가 부여된 무작위 변수로, 확률 분포가 부여된다. 

<aside>
❓

 왜 이런 확률적 접근 방식을 채택하는가 

1. 불확실한 상황에서 의사 결정을 내리는데 최적의 접근 방식이다.
2. 확률론적 모델링은 대부분은 공학 분야에서 사용하는 방식이기 때문에, 분야 간에 통일된 프레임워크로 설명할 수 있다. 
</aside>

## 1.2 Supervised learning (지도 학습)

INPUT으로 값(x)을 받고 OUTPUT(y)을 출력하는 매핑 f를 학습한다. 

INPUT x는 특징, 공변량이며, 고정된 차원의 숫자 벡터인 경우가 많다. 

OUTPUT y는 레이블, 응답 값이다. 

벡터의 차원은 벡터의 크기를 말하고, 이는 즉 입력된 특징의 수이다. 

$$
\mathcal{D} = \{(x_n, y_n)\}_{n=1}^{N},
$$

경험 D는 훈련 집합이라고 하는 N개의 입출력 쌍 집합 형태로 주어진다. (N=표본 크기)

### 1.2.1 Classification (분류)

👨‍🏫 **정의** 

정렬되지 않은 집합인 클래스가 INPUT으로 주어졌을 때, 클래스 레이블을 예측해 OUTPUT하는 것

![*pattern recognition, classification의 대표적 예시.*](image.png)

*pattern recognition, classification의 대표적 예시.*

이미지 분류에서 입력 공간 X는 이미지의 집합이다. 

컬러 이미지의 경우 

$$
D = C \times D_1 \times D_2
$$

채널(RGB) x 픽셀 차원 값(1(x),2(y))으로 계산하게 된다.

### 1.2.1.2 Exploratory data analysis

ML로 문제를 해결하기 전에 데이터 분석을 통해 확인해야 할 것

1. 확실한 패턴이 있는지
2. 데이터 자체에 문제가 없는지 ( 레이블 노이즈나 이상치)

![image.png](image%201.png)

보통은 변수 (i, j)을 선정해 산점도를 표시하고, 클래스 레이블에 따라 색으로 구분해 데이터를 표현한다.

(+) 고차원 데이터는 먼저 차원 축소를 하고 2D, 3D로 시각화

### 1.2.1.3 Learning a classifier

![재귀적으로 쌓이는 규칙](image%202.png)

재귀적으로 쌓이는 규칙

분류를 위해 하나의 규칙을 세웠는데, 이 규칙만으로 클래스(범주)를 명확하게 나누기 어렵다면, 문제를 더 작은 부분으로 나눠 새로운 규칙을 추가로 적용할 수 있다. 

⇒ 규칙을 계층적으로 쌓아가며 점차 클래스를 구분하는 능력을 높일 수 있다 !

### 1.2.1.4 Empirical risk minimization (ERM)

👨‍🏫 **역할**

1. 훈련 데이터에서의 손실을 최소화하도록 모델을 학습
2. 훈련 데이터에서의 성능을 최대화하는데 초점

⚠️ 훈련 데이터 뿐 아니라, 아직 보지 못한 미래 데이터에서의 기대 손실을 최적화해야 함 → 일반화 성능 중요

👨‍🏫 **ML의 목표**

주어진 입력에 대해 정답 라벨을 잘 예측할 수 있는 분류 모델을 만다는 것

→ 모델이 훈련 데이터를 기반으로 성능을 최적화해야 함

→ 모델 성능 평가가 계속 업데이트 되어야 함

⇒  ***분류 오류율(Misclassification Rate)***

훈련 데이터 전체에서 모델의 평균 분류 오류율

$$
\mathcal{L}(\theta) = \frac{1}{N} \sum_{n=1}^N \mathbb{I}(y_n \neq f(x_n; \theta))
$$

N : 데이터 샘플의 총 개수

I : Indicator Function (참이면 1, 거짓이면 0 반환) → 모델이 n번째 샘플 라벨 y를 잘못 예측했는지 확인 

y : n번째 샘플의 실제 라벨

f : 모델 f가 파라미터를 이용해 입력 x에 대해 예측한 라벨(값)

<aside>
❗

모든 오류가 같은 가중치를 갖는다는 가정

위 수식은 동일한 중요도를 가진다고 가정하는데, 현실에선 일부 오류가 다른 오류보다 심각할 수 있다.

ex) 식용 꽃/독성 꽃, 정상인 사람/아프지만 위독하지 않은 사람/위독한 사람

→ 이러한 문제를 해결하기 위해 각 오류에 다른 중요도를 부여하는 ***비대칭 손실 함수***가 필요하다. 

</aside>

***경험적 위험(Empirical Risk)***

모델의 평균 손실

$$
\mathcal{L}(\theta) = \frac{1}{N} \sum_{n=1}^N \ell(y_n, f(x_n; \theta))
$$

위 식과 달리, ***비대칭 손실 함수***인 l을 통해 특정 오류에 부여하는 비용을 다르게 설정할 수 있다.

![교재에 나온 꽃을 예시로 들면 이처럼 설정할 수 있을 것이다.](image%203.png)

교재에 나온 꽃을 예시로 들면 이처럼 설정할 수 있을 것이다.

### 1.2.1.5 Uncertainty (불확실성)

👨‍🏫 **정의**

모델이 INPUT 데이터를 받아, OUTPUT 값을 예측할 때 항상 맞는 결과를 낼 것이라 보장할 수 없는 것

**[ 종류 ]**  

1. *모델 불확실성  (Epistemic Uncertainty)*
    
    [ 발생 이유 ] 
    
    - 모델 자체가 학습 데이터로부터 충분히 학습하지 못함
    - 모델 구조가 적합하지 않음
    
    [ 해결 방법 ]
    
    - 더 많은 데이터를 넣어주자
    - 모델을 개선하자
2. *데이터 불확실성 (Aleatoric Uncertainty)*
    
    [ 발생 이유 ] 
    
    - 입력 데이터 자체가 본질적으로 가지고 있는 불확실성
        
        ( ex. 센서 노이즈, 데이터의 모호함 )
        
    
    [ 해결 방법 ]
    
    - 데이터를 더 많이 넣어줘도 완벽히 해결 불가

***Softmax 함수***

👨‍🏫 **정의**

조건부 확률을 계산하기 위한 함수

$$
\text{softmax}(a)_c = \frac{\exp(a_c)}{\sum_{i=1}^C \exp(a_i)}
$$

1. 모든 출력값이 0과 1 사이에 위치
2. 모든 클래스에 대한 확률의 합이 1

⇒ 각 클래스에 속할 확률을 계산해 모델의 불확실성을 정량화

***Affine 함수***

👨‍🏫 **정의**

입력 x에 대한 선형 조합을 계산한 뒤, 절편 b를 더하는 함수

$$
f(x; \theta) = b + \mathbf{w}^T \mathbf{x} = b + w_1 x_1 + w_2 x_2 + \cdots + w_D x_D
$$

절편 b를 가중치 벡터에 포함시켜 변환을 수행하면, 단순한 선형 함수로 변환된다.

$$
\tilde{\mathbf{w}}^T \tilde{\mathbf{x}} = b + \mathbf{w}^T \mathbf{x}.
$$

### 1.2.1.6 Maximum Likelihood Estimation (MLE)

👨‍🏫 **정의**

주어진 데이터에 대해 모델이 예측한 확률을 최대화하는 파라미터 θ를 찾는 과정 

⇒ 현재 관찰된 데이터를 가장 잘 설명할 수 있는 모델 파라미터(가중치, 절편)를 찾는 것

**평균 음의 로그우도 (NLL)**

$$
NLL(\theta) = -\frac{1}{N} \sum_{n=1}^N \log p(y_n | f(x_n; \theta))
$$

<aside>
❓

왜 로그와 음수를 취하는가

[ 로그 ] 

- 로그를 사용하면 곱셈 → 덧셈 연산으로 바꿀 수 있다.

⇒ 더하기 연산만 수행하므로 언더 플로우(결과가 0에 수렴)나 오버 플로우(결과가 무한대) 문제가 발생하는 것을 피할 수 있다. 

- 계산 비용이 높은 곱셈 대신 덧셈을 사용해 계산 비용을 줄일 수 있다.

[ 음수 ] 

- 로그우도 함수 자체는 최대화 하는 것이 목표이기 때문에 최소화 문제로 바꾸기 위해 음수로 만든다.

⇒ 잘못된 예측을 하면 더 큰 손실(패널티)를 부여하도록 할 수 있다.

</aside>

### 1.2.2 Regression (회귀)

👨‍🏫 **정의**

분류와 매우 유사하지만 출력값이 연속적인 실수 형태

**손실 함수**

모델이 예측한 값과 실제 값 사이의 차이를 측정하기 위해 손실 함수를 사용한다.

1. ***제곱 손실 (quadratic loss)***
    
    👨‍🏫 **정의**
    
    예측 값과 실제 값 차이를 제곱
    
    $$
     \ell_2(y, \hat{y}) = (y - \hat{y})^2
    $$
    
    **[ 효과 ]** 
    
    차이가 크면 패널티도 크게 부여
    
2. ***평균 제곱 오차 (MSE, Mean Squared Error)***
    
    👨‍🏫 **정의**
    
    모든 데이터 포인트에 대해 제곱 손실을 평균낸 값
    

$$
MSE(\theta) = \frac{1}{N} \sum_{n=1}^N \left( y_n - f(x_n; \theta) \right)^2
$$

1. ***가우시안 분포 (Gaussian)***
    
    👨‍🏫 **정의**
    
    데이터가 평균을 중심으로 대칭적으로 분포한다고 가정하는 연속 확률 분포
    

$$
 \mathcal{N}(y | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} 
    \exp{\left(-\frac{(y - \mu)^2}{2\sigma^2}\right)}
$$

<aside>
❓

왜 회귀 문제에서 MSE를 사용하는가

가우시안 분포를 기반으로 우도를 최대화하면 평균 제곱 오차(MSE)가 손실 함수로 도출된다

⇒ 음의 로그우도를 최소화하는 것은 평균 제곱 오차(MSE)를 최소화하는 것과 동일하다

</aside>

### 1.2.2.1 Linear Regression (선형 회귀)

👨‍🏫 **정의**

데이터를 가장 잘 설명하는 직선을 찾는 것

= 실제 값과 예측 값 차이를 최소화하는 것 (잔차, residual)

***잔차 제곱합 (Sum of Squared Errors, SSE)***

👨‍🏫 **정의**

모든 데이터 포인트에 대해 실제 값 (y_i)와 예측 값 f(x_i, *θ)의 차이를 제곱한 후 이를 합산한 값*

$$
 SSE = \sum_{i=1}^N (y_i - f(x_i; \theta))^2
$$

### 1.2.2.2 Polynomial regression (다항 회귀)

![화면 캡처 2025-01-15 010224.png](%25ED%2599%2594%25EB%25A9%25B4_%25EC%25BA%25A1%25EC%25B2%2598_2025-01-15_010224.png)

***WHY***

선형 회귀를 사용하면 데이터의 복잡한 패턴을 제대로 반영하지 못 한다. 

***HOW***

데이터를 더 잘 맞추기 위해 더 많은 매개변수를 사용한다 

***WHAT***

더 복잡한 다항 회귀 모델을 사용해 더 복잡하고 부드러운 곡면이 나올 수 있다. (=비선형 패턴도 설명할 수 있다)

⚠️ 모델을 과도하게 복잡하게 만들면 일반화 성능이 떨어지므로, 모델 복잡도와 데이터 간에 균형을 맞추는 것이 중요

### 1.2.2.3 Deep neural networks

차수가 너무 높으면 훈련 MSE는 계속 낮아지지만, 테스트 MSE는 다시 증가하는 과적합 문제가 발생하므로, 균형을 찾는 것이 중요하다. 

![2차 그래프 a (과소적합), 14차 그래프 b, 20차 그래프 c(과대적합), 그래프 d(MSE추이)](image%204.png)

2차 그래프 a (과소적합), 14차 그래프 b, 20차 그래프 c(과대적합), 그래프 d(MSE추이)

***과소적합 (underfitting)***

모델(다항식) 차원이 너무 낮은 것

😁 장점

데이터의 전체적인 경향을 잘 잡아낸다.

😢 단점

세부적인 패턴을 잡아내진 못 한다.

***과대적합 (overfitting)***

모델(다항식) 차원이 너무 높아 데이터의 모든 세부적인 변화를 지나치게 학습하는 것.

😁 장점

훈련 데이터는 매우 잘 맞춘다.

😢 단점

 테스트 데이터에는 일반화해 적용하지 못 한다. 

***딥러닝 모델***

각 레이어는 INPUT x를 받아 비선형 변환을 수행한다.

최종적으로 f(x;*θ)는 여러 레이어를 거쳐 나온 결과를 나타낸다.*

$$
\[f(x; \theta) = f_L(f_{L-1}(\cdots f_1(x)))\]
$$

### 1.2.3 Overfitting and generalization

***Empirical Risk (경험적 위험)***

👨‍🏫 **정의**

학습 데이터에 대한 손실 함수의 평균

$$
\mathcal{L}(\theta; D_{\text{train}}) = \frac{1}{|D_{\text{train}}|} \sum_{(x, y) \in D_{\text{train}}} \mathcal{L}(y, f(x; \theta))
$$

⇒ 모델이 학습 데이터에 대해 얼마나 잘 맞는지를 측정

***Population Risk (모집단 위험)***

👨‍🏫 **정의**

실제 데이터 분포 전체에 대한 모델 성능

$$
\mathcal{L}(\theta; \rho) = \mathbb{E}_{(x, y) \sim \rho} [\mathcal{L}(y, f(x; \theta))]
$$

⇒ 이 분포를 대부분 직접적으로 알 수 없어 경험적으로 측정이 불가능

***Test Risk (테스트 위험)***

$$
\mathcal{L}(\theta; D_{\text{test}}) = \frac{1}{|D_{\text{test}}|} \sum_{(x, y) \in D_{\text{test}}} \mathcal{L}(y, f(x; \theta))
$$

👨‍🏫 **정의**

테스트 데이터에 대한 손실의 평균

⇒ 모델의 일반화 성능을 평가하는데 사용 (=실제 환경에서의 성능을 가늠할 수 있음)

***Generalization Gap (일반화 차이)***

👨‍🏫 **정의**

모집단 위험과 경험적 위험의 차이

차이가 클수록 일반화 성능이 좋지 않은 것 (=과적합)

## 1.3 Unsupervised learning  (비지도 학습)

👨‍🏫 **정의**

입력 데이터만이 주어지고 정답이 없는 학습법

👨‍🏫 **목표**

단순히 차원을 축소하는 것이 아니라 입력 데이터 자체의 의미를 이해해 새로운 데이터의 구조나 패턴을 발견하자!

😁 장점

1. 레이블 데이터를 생성할 필요가 없음
2. 개념의 구분이 모호해 어려운 경우

<aside>
❗

확률론적 관점

지도 학습에서는 조건부 확률 분포를 학습한다. 

( 주어진 input 값에 어떤 output이 나오는지를 예측 )

반면, 비지도 학습에서는 입력 데이터 자체의 확률 분포를 학습한다.

</aside>

### 1.3.1 Clustering (클러스터링)

![image.png](image%205.png)

👨‍🏫 **목표**

입력을 '유사한' 점을 포함하는 영역으로 분할하는 것

모델 복잡성과 데이터에 대한 적합성 사이의 절충점을 고려해야 한다

### 1.3.2 Discovering latent “factors of variation” (잠재요인 발견)

고차원 데이터는 저차원 잠재 요인으로부터 생성되었다고 가정

잠재요인에 대해 간단한 확률 모델 p를 사용(가우시안 분포), 그럼 관측 데이터도 가우시안 분포를 따르는 것으로 모델링

[ 선형 모델 ] 

요인 분석(Factor Analysis, FA)

확률적 주성분 분석(Probabilistic PCA)

(+) 더 복잡한 데이터는 비선형 함수로 확장해 생각

### 1.3.3 Self-supervised learning

👨‍🏫 **정의**

레이블이 지정되지 않은 데이터에서 간접적으로 목표를 수행하도록 설계

( ex. 이미지의 한 부분을 가리고, 가려진 부분을 예측 )

***Latent factors***

관측된 데이터(표면적 데이터) 뒤에 숨어 있는 진짜 원인이나 본질적인 특징

😢 **단점**

관측 데이터에서 이러한 잠재 요인을 직접적으로 추론하려면 매우 복잡한 계산과 높은 수준의 모델링이 필요함. 

⇒  Self-supervised learning은 잠재 요인을 직접 추론하려고 하지 않고, 프록시 과제를 통해 유용한 feature를 학습함 → 이를 통해 관측한 데이터 안에서 의미 있는 패턴을 학습

### 1.3.4 Evaluating unsupervised learning

👨‍🏫 **정의**

모르는 테스트 예제에 대해 모델이 할당하는 확률을 측정

⇒ 비지도 학습 문제를 밀도 추정의 문제로 취급 

( 모델이 데이터 샘플이 나온 영역에 높은 확률을 할당하면, 데이터가 나오지 않는 영역에는 암묵적으로 낮은 확률을 할당 → 모델은 데이터의 일반적인 패턴을 포착 )

⚠️ 고차원에선 사용하기 어렵고, 패턴을 학습하지 못 했을 수도 있다.

## 1.4 Reinforcement learning (강화 학습)

👨‍🏫 **정의**

시스템이나 에이전트가 환경과 상호 작용하며 학습

환경에서 파생된 가능한 입력 x에 대해 취할 조치를 지정

**[ 특징 ]** 

시스템에 어떤 동작이 가장 좋은지 알려주지 않고, 보상만 줌

⚠️ 보상 신호가 왔을 때, 에이전트가 자신의 여러 행동 중 어떤 행동이 보상을 받는 데 기여했는지 불분명할 수 있음